{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CorpusReaders import Elsevier_Corpus_Reader, Corpus_Pre_Processor, Elsivier_Ingestor, Corpus_filters\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta review of soft robots using the scopus database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1: download the raw corpus from elsivier\n",
    "* search the Scopus database for the term 'soft robot\n",
    "* search over the date range 1950 to 2021\n",
    "* Downloaded on date 26 August 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_corpus() -> None:\n",
    "    \"\"\"\n",
    "    download a all papers for a given search term for a given year.\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    builder = Elsivier_Ingestor.ScopusIngestionEngine(\n",
    "        file_path=\"Corpus/Raw_corpus/\",\n",
    "        home=False,\n",
    "        batch_size=25)\n",
    "\n",
    "    builder.build_corpus(search_terms=['soft robot'],\n",
    "                         dates=(1950, 2021))\n",
    "    \n",
    "if False:\n",
    "    download_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2: refactor the corpus\n",
    "* The corpus is downloaded as collections containing all publications\n",
    "  within a given year. This step splits these collections into\n",
    "  individual documents that can be accessed independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor_corpus() -> None:\n",
    "    \"\"\"\n",
    "    Read the raw corpus and refactor the collections from a single file per\n",
    "    year to a single file per document.\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    root = \"Corpus/Raw_corpus/\"\n",
    "    target = \"Corpus/Split_corpus/\"\n",
    "\n",
    "    corpus = Elsevier_Corpus_Reader.RawCorpusReader(root=root)\n",
    "    Corpus_Pre_Processor.split_corpus(corpus=corpus, target=target)\n",
    "    \n",
    "if False:\n",
    "    refactor_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 3: Pre process the corpus to clean and format the data.\n",
    "* tokenize text into format where one document returns\n",
    "    list of paragraphs\n",
    "        list of sentences\n",
    "            list of tagged tokens\n",
    "                (token, tag)\n",
    "* tokenize additional text fields such as author, city, journal names\n",
    "* add the file path each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus() -> None:\n",
    "    \"\"\"\n",
    "    processes and refomats both text and meta data\n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \"\"\"\n",
    "    corp = Elsevier_Corpus_Reader.ScopusCorpusReader(\n",
    "            \"Corpus/Split_corpus/\")\n",
    "\n",
    "    formatter = Corpus_Pre_Processor.ScopusCorpusProcessor(corp)\n",
    "    formatter.transform()\n",
    "\n",
    "if False:\n",
    "    preprocess_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 4: Preliminary exploration of the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details of the corpus by the numbers\n",
    "### What text data do we have?\n",
    "\n",
    "### Journals?\n",
    "* How many unique juournals?\n",
    "* Distribution of unique journals per year?\n",
    "* Distribution new unique journals per year?\n",
    "* plot publications per journal\n",
    "* cluster papers by content and label by journal\n",
    "### Publications?\n",
    "* Total number of publications\n",
    "* plot publications per year \n",
    "* plot cumulative publications over time\n",
    "* plot distribution of citations per publication\n",
    "* What subtypes of publications are covered\n",
    "* plot the counts per subtype\n",
    "* plot num publications per country\n",
    "* plot num publications per institution\n",
    "\n",
    "### Topics and meta..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What text data do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'description_lexical_diversity': 334.92504354500636,\n",
      "    'description_num': 58711,\n",
      "    'description_vocab': 99243,\n",
      "    'description_word_count': 11344916,\n",
      "    'description_words_per_description': 193.2332271635639,\n",
      "    'descriptions_per_doc': 1.0,\n",
      "    'files': 58711,\n",
      "    'time_to_process': 29.555049419403076,\n",
      "    'title_lexical_diversity': 21.424763085643434,\n",
      "    'title_num': 58711,\n",
      "    'title_vocab': 33873,\n",
      "    'title_word_count': 725721,\n",
      "    'title_words_per_title': 12.360903408219924,\n",
      "    'titles_per_doc': 1.0,\n",
      "    'topics': 1}\n"
     ]
    }
   ],
   "source": [
    "root = \"Corpus/Split_corpus/\"\n",
    "corpus = Elsevier_Corpus_Reader.ScopusProcessedCorpusReader(root)\n",
    "pp.pprint(corpus.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors?\n",
    "* How many unique authors?\n",
    "    * count the number of unique auther ids >\n",
    "* Distribution of unique authors per year?\n",
    "* Cumulative distribution of unique authors per year? \n",
    "* Distribution new unique authors per year?\n",
    "* Cumulative distribution of new unique authors per year? \n",
    "* Distribution of papers published by each author?\n",
    "* Distribution of total citation count by author?\n",
    "* Distribution of author count per paper?\n",
    "* Distribution of total number of co-authors per author?\n",
    "* author colaboration network?\n",
    "* plot author cluster by paper content?\n",
    "* plot map of authors by country\n",
    "* plot map of authors by institution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Author count: 216300\n",
      "Unique Author count: 116586\n",
      "Max number of Author occurance: 382\n",
      "Average number of Author occurance: 1.8552827955329114\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "author_counts = Counter(corpus.author_data_id_s())\n",
    "print(\"Total Author count: {}\".format(np.sum(list(author_counts.values()))))\n",
    "print(\"Unique Author count: {}\".format(len(set(author_counts.keys()))))\n",
    "print(\"Max number of Author occurance: {}\".format(np.max(list(author_counts.values()))))\n",
    "print(\"Average number of Author occurance: {}\".format(np.mean(list(author_counts.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.countplot(list(author_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(list(author_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_gen = Corpus_filters.CorpusFrameGenerator(root=root)\n",
    "corpus_frame = C_gen.generate_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_frame.loc[\"soft robot/00175d8bafa40eaa0807694ca814f5c9.pickle\", \"author\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_authors_count(row):\n",
    "    detail = 'authid' \n",
    "    authors = []\n",
    "    if row is not np.NaN:\n",
    "        for author in row:\n",
    "            authors.append(author[detail])\n",
    "        return authors\n",
    "    else:\n",
    "        return []\n",
    "\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = Counter(corpus_frame.loc[:, 'author'].apply(get_authors_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = corpus_frame.loc[:, 'author'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.melt(a,id_vars=['Captured_Date','Brand','Coverage'],value_name='Keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fictional-barnical-no-accelerat] *",
   "language": "python",
   "name": "conda-env-fictional-barnical-no-accelerat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
